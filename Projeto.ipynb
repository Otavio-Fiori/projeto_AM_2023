{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importa os pacotes necessários\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from pandas.plotting import scatter_matrix\n",
    "import seaborn as sns\n",
    "from scipy import stats as ss\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import tree\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carrega os dados\n",
    "df = pd.read_csv('dados/BankChurners.csv',low_memory=False)\n",
    "\n",
    "# head dos dados\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tamanho do dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribuição da variável target\n",
    "df.Attrition_Flag.value_counts().plot.pie(autopct='%1.1f%%',figsize=(10,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove as colunas que não vamos utilizar\n",
    "df = df[df.columns[:-2]]\n",
    "\n",
    "# cria coluna com flag de churn\n",
    "df['Churn'] = df['Attrition_Flag'].apply(lambda x: 1 if x == 'Attrited Customer' else 0)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Definição de Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(y_true, y_pred, label, x_size=5, y_size=5, savepath=None):\n",
    "    \"\"\"\n",
    "    Plots a confusion matrix\n",
    "\n",
    "    Params:\n",
    "        - y_true: the true value of the target\n",
    "        - y_pred: the predicted value of the data\n",
    "        - label: the name of the model\n",
    "        - - x_size: x size of the plot\n",
    "        - y_size: y size of the plot\n",
    "        - savepath: the path to save the image\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=np.unique(y_true))\n",
    "    cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
    "    cm_perc = cm / cm_sum.astype(float) * 100\n",
    "    annot = np.empty_like(cm).astype(str)\n",
    "    nrows, ncols = cm.shape\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            c = cm[i, j]\n",
    "            p = cm_perc[i, j]\n",
    "            if i == j:\n",
    "                s = cm_sum[i]\n",
    "                annot[i, j] = \"%.1f%%\\n%d/%d\" % (p, c, s)\n",
    "            elif c == 0:\n",
    "                annot[i, j] = \"\"\n",
    "            else:\n",
    "                annot[i, j] = \"%.1f%%\\n%d\" % (p, c)\n",
    "    cm = pd.DataFrame(cm, index=np.unique(y_true), columns=np.unique(y_true))\n",
    "    cm.index.name = \"Actual\"\n",
    "    cm.columns.name = \"Predicted\"\n",
    "    fig, ax = plt.subplots(figsize=(x_size, y_size))\n",
    "    plt.title(\"Matriz de Confusão - \" + label, fontsize=15)\n",
    "    sns.heatmap(cm, cmap=\"Blues\", annot=annot, fmt=\"\", ax=ax)\n",
    "    # savesfig\n",
    "    if savepath is not None:\n",
    "        plt.savefig(savepath + \".png\")\n",
    "    plt.show()\n",
    "    return cm\n",
    "\n",
    "\n",
    "def class_def(multi, y_proba):\n",
    "    \"Helper function of the plot_roc_curve function\"\n",
    "    if multi is False:\n",
    "        return [0]\n",
    "    else:\n",
    "        return range(len(y_proba[0]))\n",
    "\n",
    "\n",
    "# função para plotar a curva ROC\n",
    "def plot_roc_curve(\n",
    "    y_true, y_proba, label, x_size=5, y_size=5, savepath=None, strategy=\"ovo\"\n",
    "):\n",
    "\n",
    "    \"\"\"\n",
    "    Plots the roc auc curve.\n",
    "\n",
    "    Params:\n",
    "        - y_true: the true value of the target\n",
    "        - y_proba: the predicted probability value of the data\n",
    "        - label: the name of the model\n",
    "        - - x_size: x size of the plot\n",
    "        - y_size: y size of the plot\n",
    "        - savepath: the path to save the image\n",
    "    \"\"\"\n",
    "\n",
    "    # checks if it is multiclass\n",
    "    if pd.Series(y_true).nunique() > 2:\n",
    "        multi = True\n",
    "    else:\n",
    "        multi = False\n",
    "\n",
    "    # creates no skill probas\n",
    "    ns_probs = [0 for _ in range(len(y_true))]\n",
    "    ns_true = [random.randint(0, 1) for _ in range(len(y_true))]\n",
    "    ns_auc = roc_auc_score(ns_true, ns_probs)\n",
    "    ns_fpr, ns_tpr, _ = roc_curve(ns_true, ns_probs)\n",
    "\n",
    "    # keeps only the positive value if not multiclass\n",
    "    if multi is False:\n",
    "        try:\n",
    "            y_proba = y_proba[:, 1]\n",
    "        except Exception:\n",
    "            y_proba = y_proba\n",
    "\n",
    "    # calculates model ROC AUC SCORE\n",
    "    if multi is True:\n",
    "        model_auc = roc_auc_score(\n",
    "            y_true, y_proba, multi_class=strategy, average=\"weighted\"\n",
    "        )\n",
    "    else:\n",
    "        model_auc = roc_auc_score(y_true, y_proba)\n",
    "\n",
    "    fpr = {}\n",
    "    tpr = {}\n",
    "    thresh = {}\n",
    "    n_class = class_def(multi, y_proba)\n",
    "    if multi is True:\n",
    "        for i in n_class:\n",
    "            fpr[i], tpr[i], thresh[i] = roc_curve(\n",
    "                y_true,\n",
    "                y_proba[:, i],\n",
    "                pos_label=i\n",
    "                )\n",
    "    else:\n",
    "        for i in n_class:\n",
    "            fpr[i], tpr[i], thresh[i] = roc_curve(y_true, y_proba)\n",
    "\n",
    "    # summarize scores\n",
    "    print(\"No Skill: ROC AUC=%.3f\" % (ns_auc))\n",
    "    print(label + \": ROC AUC=%.3f\" % (model_auc))\n",
    "\n",
    "    # plots the ROC Curve\n",
    "    fig, ax = plt.subplots(figsize=(x_size, y_size))\n",
    "\n",
    "    # define the colors\n",
    "    colors_ls = [\"b\", \"g\", \"r\", \"c\", \"m\", \"y\", \"k\", \"w\"]\n",
    "    colors = []\n",
    "    cont = 0\n",
    "    while len(colors) < len(n_class):\n",
    "        if cont == len(colors_ls):\n",
    "            cont = 0\n",
    "        colors.append(colors_ls[cont])\n",
    "        cont += 1\n",
    "\n",
    "    # creates plots\n",
    "    for i in n_class:\n",
    "        plt.plot(\n",
    "            fpr[i],\n",
    "            tpr[i],\n",
    "            linestyle=\"-\",\n",
    "            color=colors[i],\n",
    "            label=f\"Class {i+1}\"\n",
    "            )\n",
    "    plt.plot(ns_fpr, ns_tpr, linestyle=\"--\", label=\"No Skill\")\n",
    "\n",
    "    # axis labels\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    # plot title\n",
    "    plt.title(f\"ROC AUC Curve - {label}\", fontsize=15)\n",
    "    # show legend\n",
    "    plt.legend(loc=\"best\")\n",
    "    # savesfig\n",
    "    if savepath is not None:\n",
    "        plt.savefig(savepath + \".png\")\n",
    "    # show the plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def tree_plot(modelo, X, x_size=5, y_size=5, savepath=None):\n",
    "    \"\"\"\n",
    "    Plots the tree for tree based models.\n",
    "\n",
    "    Params:\n",
    "        - model: a sklearn trained model\n",
    "        - X: the input data\n",
    "        - x_size: x size of the plot\n",
    "        - y_size: y size of the plot\n",
    "        - savepath: the path to save the image\n",
    "    \"\"\"\n",
    "    # tamanho do plot\n",
    "    plt.figure(figsize=(x_size, y_size))\n",
    "\n",
    "    # árvore criada\n",
    "    tree.plot_tree(\n",
    "        decision_tree=modelo,  # modelo criado\n",
    "        feature_names=X.columns,  # lista de variáveis\n",
    "        label=\"all\",  # mostra os dados em todos os nós\n",
    "        filled=True,  # pinta os nós com maior volumetria\n",
    "        rounded=True,  # plota cada nó com pontas arredondadas\n",
    "        fontsize=10,  # define o tamanho da fonte\n",
    "    )\n",
    "\n",
    "    # savesfig\n",
    "    if savepath is not None:\n",
    "        plt.savefig(savepath + \".png\")\n",
    "\n",
    "def clasifiers_test(\n",
    "            X, Y, modelos, num_folds, metrica, x_size=5, y_size=5, savepath=None):\n",
    "        \"\"\"\n",
    "        This function tests multiple clasifiers with cross validation\n",
    "        and prints their scores.\n",
    "\n",
    "        Params:\n",
    "            - X: the input data\n",
    "            - Y: the target data\n",
    "            - num_folds: the number of folds to use\n",
    "                in cross validation\n",
    "            - x_size: x size of the plot\n",
    "            - y_size: y size of the plot\n",
    "            - savepath: the path to save the image\n",
    "        \"\"\"\n",
    "        # Avaliando cada modelo em um loop\n",
    "        resultados = []\n",
    "\n",
    "        nomes = []\n",
    "\n",
    "        print(f\"MODELO\\t|\\t  MEDIA  \\t|\\tDESVIO\")\n",
    "        for nome, modelo in modelos:\n",
    "            kfold = KFold(n_splits=num_folds)\n",
    "            cv_results = cross_val_score(\n",
    "                modelo,\n",
    "                X,\n",
    "                Y,\n",
    "                cv=kfold,\n",
    "                scoring=metrica\n",
    "                )\n",
    "            resultados.append(cv_results)\n",
    "            nomes.append(nome)\n",
    "            msg = \"%s\\t|\\t%f\\t|\\t%f\" % (\n",
    "                nome,\n",
    "                cv_results.mean(),\n",
    "                cv_results.std()\n",
    "                )\n",
    "            print(msg)\n",
    "\n",
    "        # Boxplot para comparar os algoritmos\n",
    "        fig = plt.figure(figsize=(x_size, y_size))\n",
    "        fig.suptitle(\"Comparação de Algoritmos de Classificação\")\n",
    "        ax = fig.add_subplot(111)\n",
    "        plt.boxplot(resultados)\n",
    "        ax.set_xticklabels(nomes)\n",
    "        # savesfig\n",
    "        if savepath is not None:\n",
    "            plt.savefig(savepath + \".png\")\n",
    "        plt.show()\n",
    "        return pd.DataFrame(\n",
    "            resultados,\n",
    "            columns=[f\"fold_{i}\" for i in range(num_folds)],\n",
    "            index=nomes\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Definição de Variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tipos dos dados\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variáveis contínuas\n",
    "continuas = [\n",
    "    'Customer_Age',\n",
    "    'Dependent_count',\n",
    "    'Months_on_book',\n",
    "    'Total_Relationship_Count',\n",
    "    'Months_Inactive_12_mon',\n",
    "    'Contacts_Count_12_mon',\n",
    "    'Credit_Limit',\n",
    "    'Total_Revolving_Bal',\n",
    "    'Avg_Open_To_Buy',\n",
    "    'Total_Amt_Chng_Q4_Q1',\n",
    "    'Total_Trans_Amt',\n",
    "    'Total_Trans_Ct',\n",
    "    'Total_Ct_Chng_Q4_Q1',\n",
    "    'Avg_Utilization_Ratio'\n",
    "]\n",
    "\n",
    "# variáveis categóricas\n",
    "categoricas = [\n",
    "    'Gender',\n",
    "    'Education_Level',\n",
    "    'Marital_Status',\n",
    "    'Income_Category',\n",
    "    'Card_Category'\n",
    "]\n",
    "\n",
    "# resposta\n",
    "resposta = ['Churn']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Análise Exploratória"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Variáveis Contínuas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[continuas].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faz um plot de densidade das variávels contínuas\n",
    "df[continuas].plot(\n",
    "    kind=\"density\",\n",
    "    subplots=True,\n",
    "    sharex=False,\n",
    "    figsize=(10, 10)\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que as variáveis contínuas não seguem uma distribuição normal e por isso devemos tomar alguns cuidados na hora de testar uma Regressão Logística por exemplo por ser uma técnica que tem como premissa que as variáveis explicativas seguem uma distribuição normal, o correto seria padronizar os dados antes do treinamento para que a média seja 0 e o desvio padrão 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[continuas].plot(\n",
    "        kind=\"box\",\n",
    "        subplots=True,\n",
    "        sharex=False,\n",
    "        figsize=(30, 10)\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos agora verificar que algumas das nossas variáveis têm muitos outliers, por isso, é necessário realizar uma padronização antes de utilizarmos um algoritmo que calcula distâncias como o KNN, por exemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[continuas + resposta].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cria matriz de correlação\n",
    "correlations = df[continuas + resposta].corr()\n",
    "\n",
    "# cria figura\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "\n",
    "# cria a máscara\n",
    "mask = np.zeros_like(correlations, dtype=bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# cria eixos\n",
    "with sns.axes_style(\"white\"):\n",
    "    sns.heatmap(\n",
    "        correlations,\n",
    "        mask=mask,\n",
    "        vmin=-1,\n",
    "        vmax=1,\n",
    "        square=True,\n",
    "        annot=True,\n",
    "        fmt=\".2f\",\n",
    "        linewidths=0.5,\n",
    "        cmap=sns.color_palette(\"Spectral\"),\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver pelo gráfico acima que algumas variáveis tem uma correlação muito alta entre elas, como por exemplo as variáveis Credit_Limit e Avg_Open_To_Buy que tem uma correlação perfeita e igual a 1."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Variáveis Categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gráfico de distribuição das variáveis categoricas\n",
    "for col in categoricas:\n",
    "    df.groupby([col, 'Churn']).size().groupby(level=0).apply(lambda x: 100 * x / x.sum()).unstack().plot(\n",
    "        kind='bar',\n",
    "        stacked=True,\n",
    "        figsize=(5,5),\n",
    "        title=col\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos perceber que a Categoria do Cartão de Crédito, a Categoria de Renda e o Nível Educacional são as variáveis que mais distorcem a distribuição de churn."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Preparação dos Dados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Modelagem sem DataPrep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separa variáveis preditoras e variável resposta\n",
    "X = df[categoricas + continuas]\n",
    "Y = df[\"Churn\"]\n",
    "\n",
    "# cria os dummies\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# cria uma lista de modelos para testar\n",
    "modelos = []\n",
    "modelos.append((\"LR\", LogisticRegression(max_iter=5000)))\n",
    "modelos.append((\"NB\", GaussianNB()))\n",
    "modelos.append((\"KNN\", KNeighborsClassifier()))\n",
    "modelos.append((\"CART\", DecisionTreeClassifier()))\n",
    "modelos.append((\"RF\", RandomForestClassifier()))\n",
    "modelos.append((\"SVM\", SVC()))\n",
    "modelos.append((\"GB\", GradientBoostingClassifier()))\n",
    "\n",
    "# testa os modelos\n",
    "clasifiers_test(X=X, Y=Y, modelos = modelos, num_folds=5, metrica=\"roc_auc\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste primeiro teste podemos verificar que os algoritmos Gradient Boosting, Random Forest, Naive Bayes e Regressão Logísitica tiveram melhor performance e também foram mais estáveis tendo um desvio padrão mais baixo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Modelagem com DataPrep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cria uam cópia do df para o pré-processamento\n",
    "df_pre = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cria a correlação\n",
    "correlacao = df[continuas + resposta].corr()\n",
    "\n",
    "# lista de pares de variáveis correlacionadas\n",
    "pares = []\n",
    "\n",
    "# loop para encontrar as variáveis correlacionadas\n",
    "for index,row in correlacao.iterrows():\n",
    "    for col in correlacao.columns:\n",
    "        # se o valor absoluto for maior que 0.7 e não for a mesma variável appenda o par de variáveis\n",
    "        if index != col and index != resposta[0] and col != resposta[0] and abs(correlacao.loc[index,col]) > 0.7:\n",
    "            pares.append((index,col))\n",
    "\n",
    "# lista de variáveis a serem excluídas\n",
    "excluir = []\n",
    "\n",
    "# loop para encontrar as variáveis a serem excluídas\n",
    "for col1,col2 in pares:\n",
    "    # se o valor absoluto da correlação da variável com a resposta for maior que o \n",
    "    # valor absoluto da correlação da outra variável com a resposta\n",
    "    # então appenda a variável com menor correlação\n",
    "    if abs(correlacao.loc[col1,'Churn']) >= abs(correlacao.loc[col2,'Churn']):\n",
    "        excluir.append(col2)\n",
    "    else:\n",
    "        excluir.append(col1)\n",
    "print(f'Variáveis para excluir por alta correlação: {excluir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definição do skew maximo\n",
    "skew_max = 0.5\n",
    "\n",
    "# calculo do skew da variáveis contínuas\n",
    "continuas_finais = [col for col in continuas if col not in excluir]\n",
    "skew = df_pre[continuas_finais].skew()\n",
    "\n",
    "# cria lista com variáveis que precisam de transformação\n",
    "skew = skew[abs(skew) > skew_max]\n",
    "skew = skew.index.tolist()\n",
    "print(skew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agora vamos normalizar as variáveis para que tenham média 0 e desvio padrão 1\n",
    "scaler = StandardScaler()\n",
    "df_pre[skew] = scaler.fit_transform(df_pre[skew])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separa variáveis preditoras e variável resposta\n",
    "X = df_pre[categoricas + continuas]\n",
    "Y = df_pre[\"Churn\"]\n",
    "\n",
    "# cria os dummies\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# cria uma lista de modelos para testar\n",
    "modelos = []\n",
    "modelos.append((\"LR\", LogisticRegression(max_iter=5000)))\n",
    "modelos.append((\"NB\", GaussianNB()))\n",
    "modelos.append((\"KNN\", KNeighborsClassifier()))\n",
    "modelos.append((\"CART\", DecisionTreeClassifier()))\n",
    "modelos.append((\"RF\", RandomForestClassifier()))\n",
    "modelos.append((\"SVM\", SVC()))\n",
    "modelos.append((\"GB\", GradientBoostingClassifier()))\n",
    "\n",
    "# testa os modelos\n",
    "clasifiers_test(X=X, Y=Y, modelos = modelos, num_folds=5, metrica=\"roc_auc\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste segundo teste podemos verificar que os algoritmos que tiveram boa performance no teste anterior continuaram tendo boa performance. As diferenças de fato estão na Regressão Logística e no Naive Bayes, no caso da regressão mesmo utilizando menos variáveis preditoras vemos que teve uma pequena melhora pois no segundo dataset criado as variáveis seguem as premissas do algoritmo, já no caso do Naive Bayes mesmo seguindo as premissas necessárias acabou perdendo um pouco de performance.\n",
    "\n",
    "Outro ponto interessante é que os demais modelos mantiveram seus resultados mesmo descartando 4 variáveis, mostrando que remover variáveis não necessariamente diminui a performance do modelo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Modelagem"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Baseline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como modelo base neste case vamos utilizar a Regressão Logística por ter alta performance e ser o modelo linear e o Gradient Boosting por ter atingido a mais alta performance dos modelos testados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separa variáveis preditoras e variável resposta\n",
    "X = df_pre[categoricas + continuas]\n",
    "Y = df_pre[\"Churn\"]\n",
    "\n",
    "# cria os dummies\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# separa os dados entre treino e teste\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cria o modelo baseline de regressão logística\n",
    "modelo_rl = LogisticRegression(max_iter=5000)\n",
    "\n",
    "# treina o modelo\n",
    "modelo_rl.fit(X_train, Y_train)\n",
    "\n",
    "# faz as previsões com dados de teste\n",
    "Y_pred = modelo_rl.predict(X_test)\n",
    "Y_pred_proba = modelo_rl.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# faz as previsões com dados de treino\n",
    "Y_pred_train = modelo_rl.predict(X_train)\n",
    "Y_pred_proba_train = modelo_rl.predict_proba(X_train)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostra a importância das variáveis\n",
    "importancia = pd.DataFrame({\"Variavel\": X_train.columns, \"Importancia\": modelo_rl.coef_[0]})\n",
    "importancia.sort_values(\"Importancia\", ascending=False).plot.bar(x=\"Variavel\", y=\"Importancia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plota a matriz de confusão de teste\n",
    "plot_cm(Y_test, Y_pred, 'Regressão Logística - Teste')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plota a matriz de confusão de treino \n",
    "plot_cm(Y_train, Y_pred_train, 'Regressão Logística - Treino')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos perceber que a matriz de confusão ficou com uma acurácia baixa neste modelo porém isso se deve ao fato de termos uma resposta com dados desbalanceados. Para melhor avaliarmos o modelo precisamos plotar a curva roc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plota a curva ROC de teste\n",
    "plot_roc_curve(Y_test, Y_pred_proba, 'Regressão Logística - Teste')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plota a curva ROC de treino\n",
    "plot_roc_curve(Y_train, Y_pred_proba_train, 'Regressão Logística - Treino')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC é uma curva de probabilidade e AUC representa o grau ou medida de separabilidade. Diz o quanto o modelo é capaz de distinguir entre as classes. Quanto maior a AUC, melhor será o modelo.\n",
    "\n",
    "Aqui atingimos 0.918 em treino e 0.920 em teste, resultados bastante parecidos, o que nos indica que não houve overfitting e por ser um resultado bom também não houve underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plota um histograma com as probabilidades de churn\n",
    "df_result = pd.DataFrame({'Churn':Y_test, 'Churn_Prob':Y_pred_proba})\n",
    "sns.histplot(data=df_result,x = 'Churn_Prob',hue='Churn', bins=20, kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plota um histograma com as probabilidades de churn\n",
    "df_result = pd.DataFrame({'Churn':Y_train, 'Churn_Prob':Y_pred_proba_train})\n",
    "sns.histplot(data=df_result,x = 'Churn_Prob',hue='Churn', bins=20, kde=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pelos histogramas acima podemos ver que a classe 1 ainda não está tão separada da classe 0 quanto pretendemos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cria o modelo baseline de gradient boosting\n",
    "modelo_gb = GradientBoostingClassifier()\n",
    "\n",
    "# treina o modelo\n",
    "modelo_gb.fit(X_train, Y_train)\n",
    "\n",
    "# faz as previsões com dados de teste\n",
    "Y_pred = modelo_gb.predict(X_test)\n",
    "Y_pred_proba = modelo_gb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# faz as previsões com dados de treino\n",
    "Y_pred_train = modelo_gb.predict(X_train)\n",
    "Y_pred_proba_train = modelo_gb.predict_proba(X_train)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostra a importância das variáveis\n",
    "importancia = pd.DataFrame({\"Variavel\": X_train.columns, \"Importancia\": modelo_gb.feature_importances_})\n",
    "importancia.query(\"Importancia > 0\").sort_values(\"Importancia\", ascending=False).plot.bar(x=\"Variavel\", y=\"Importancia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plota a matriz de confusão de teste\n",
    "plot_cm(Y_test, Y_pred, 'Gradient Boosting - Teste')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plota a matriz de confusão de treino\n",
    "plot_cm(Y_train, Y_pred_train, 'Gradient Boosting - Treino')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui podemos perceber que o Gradient Boosting conseguiu resolver relativamente bem o desbalanceamento da base acertando 89% dos clientes com churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plota a curva ROC de teste\n",
    "plot_roc_curve(Y_test, Y_pred_proba, 'Gradient Boosting - Teste')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plota a curva ROC de teste\n",
    "plot_roc_curve(Y_train, Y_pred_proba_train, 'Gradient Boosting - Treino')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com o Gradient Boosting podemos visualizar que o algoritmo ficou com uma ROC AUC Score bem próximo do perfeito nos resultados de treino e acabou descolando um pouco dos dados de teste, indicando um leve overfitting no mesmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plota um histograma com as probabilidades de churn\n",
    "df_result = pd.DataFrame({'Churn':Y_test, 'Churn_Prob':Y_pred_proba})\n",
    "sns.histplot(data=df_result,x = 'Churn_Prob',hue='Churn', bins=20, kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plota um histograma com as probabilidades de churn\n",
    "df_result = pd.DataFrame({'Churn':Y_train, 'Churn_Prob':Y_pred_proba_train})\n",
    "sns.histplot(data=df_result,x = 'Churn_Prob',hue='Churn', bins=20, kde=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nestes histogramas já podemos perceber que há uma clara diferença entre as classes indicando que o modelo consegue separar ambas muito bem."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.1 Ajustando Hiperparâmetros"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos modelos baseline não ajustamos nenhum hiperparâmetro e podemos melhorar os nossos resultados encontrando o melhor conjunto para cada modelo.\n",
    "\n",
    "Neste teste vamos alterar os principais hiperparâmetros de cada algoritmo:\n",
    "\n",
    "- Regressão Logística:\n",
    "    - Penalty: podemos a penalização de variáveis para melhor ajustar os coeficientes do modelo\n",
    "    - C: inverso da força de penalização\n",
    "\n",
    "\n",
    "- Gradient Boosting:\n",
    "    - learning_rate: taxa de aprendizado do modelo\n",
    "    - n_estimators: número de árvores de regressão utilizadas pelo modelo\n",
    "    - min_samples_leaf: quantidade mínima de dados em uma folha\n",
    "    - max_depth: profundidade máxima das árvores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.1 Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define os hiperparametros\n",
    "parametros = {\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'min_samples_leaf': [0.05,0.1,0.2],\n",
    "        'max_depth': [3, 5, 7, 9],\n",
    "        }\n",
    "\n",
    "# parametros = {\n",
    "#         'learning_rate': [0.05, 0.1],\n",
    "#         'n_estimators': [100],\n",
    "#         'min_samples_leaf': [0.1,0.2],\n",
    "#         'max_depth': [ 7, 9],\n",
    "#         }\n",
    "\n",
    "\n",
    "# define o modelo\n",
    "modelo_gb = GradientBoostingClassifier()\n",
    "\n",
    "# define a estratégia de busca\n",
    "grid_gb = GridSearchCV(modelo_gb, parametros, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "# treina o modelo\n",
    "grid_gb.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imprime os melhores parâmetros\n",
    "print(f'Os melhores parâmetros encontrados foram: {grid_gb.best_params_}')\n",
    "\n",
    "# coloca os resultados em um dataframe\n",
    "resultados = pd.DataFrame(grid_gb.cv_results_)\n",
    "resultados = resultados.sort_values('mean_test_score', ascending=False)\n",
    "resultados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treina o modelo com os melhores parâmetros\n",
    "modelo_gb = GradientBoostingClassifier(\n",
    "    learning_rate=grid_gb.best_params_['learning_rate'],\n",
    "    max_depth=grid_gb.best_params_['max_depth'],\n",
    "    min_samples_leaf=grid_gb.best_params_['min_samples_leaf'],\n",
    "    n_estimators=grid_gb.best_params_['n_estimators']\n",
    ")\n",
    "\n",
    "# treina o modelo\n",
    "modelo_gb.fit(X_train, Y_train)\n",
    "\n",
    "# faz as previsões com dados de teste\n",
    "Y_pred = modelo_gb.predict(X_test)\n",
    "Y_pred_proba = modelo_gb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# faz as previsões com dados de treino\n",
    "Y_pred_train = modelo_gb.predict(X_train)\n",
    "Y_pred_proba_train = modelo_gb.predict_proba(X_train)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plota a matriz de confusão de teste\n",
    "plot_cm(Y_test, Y_pred, 'Gradient Boosting - Teste')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plota a matriz de confusão de treino\n",
    "plot_cm(Y_train, Y_pred_train, 'Gradient Boosting - Treino')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plota a curva ROC de teste\n",
    "plot_roc_curve(Y_test, Y_pred_proba, 'Gradient Boosting - Teste')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plota a curva ROC de teste\n",
    "plot_roc_curve(Y_train, Y_pred_proba_train, 'Gradient Boosting - Treino')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plota um histograma com as probabilidades de churn\n",
    "df_result = pd.DataFrame({'Churn':Y_test, 'Churn_Prob':Y_pred_proba})\n",
    "sns.histplot(data=df_result,x = 'Churn_Prob',hue='Churn', bins=20, kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plota um histograma com as probabilidades de churn\n",
    "df_result = pd.DataFrame({'Churn':Y_train, 'Churn_Prob':Y_pred_proba_train})\n",
    "sns.histplot(data=df_result,x = 'Churn_Prob',hue='Churn', bins=20, kde=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.2 Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define os hiperparametros\n",
    "parametros = {\n",
    "        'penalty': ['l1','l2','elasticnet'],\n",
    "        'C': [1,0.5,0.1],\n",
    "        'max_iter': [5000, 10000, 20000]\n",
    "        }\n",
    "\n",
    "\n",
    "# define o modelo\n",
    "modelo_rl = LogisticRegression()\n",
    "\n",
    "# define a estratégia de busca\n",
    "grid_rl = GridSearchCV(modelo_rl, parametros, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "# treina o modelo\n",
    "grid_rl.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imprime os melhores parâmetros\n",
    "print(f'Os melhores parâmetros encontrados foram: {grid_rl.best_params_}')\n",
    "\n",
    "# coloca os resultados em um dataframe\n",
    "resultados = pd.DataFrame(grid_rl.cv_results_)\n",
    "resultados = resultados.sort_values('mean_test_score', ascending=False)\n",
    "resultados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treina o modelo com os melhores parâmetros\n",
    "modelo_rl = LogisticRegression(\n",
    "    C=grid_rl.best_params_['C'],\n",
    "    max_iter=grid_rl.best_params_['max_iter'],\n",
    "    penalty=grid_rl.best_params_['penalty']\n",
    ")\n",
    "\n",
    "# treina o modelo\n",
    "modelo_rl.fit(X_train, Y_train)\n",
    "\n",
    "# faz as previsões com dados de teste\n",
    "Y_pred = modelo_rl.predict(X_test)\n",
    "Y_pred_proba = modelo_rl.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# faz as previsões com dados de treino\n",
    "Y_pred_train = modelo_rl.predict(X_train)\n",
    "Y_pred_proba_train = modelo_rl.predict_proba(X_train)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plota a matriz de confusão de teste\n",
    "plot_cm(Y_test, Y_pred, 'Regressão Logística - Teste')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plota a matriz de confusão de teste\n",
    "plot_cm(Y_train, Y_pred_train, 'Regressão Logística - Treino')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plota a curva ROC de teste\n",
    "plot_roc_curve(Y_test, Y_pred_proba, 'Regressão Logística - Teste')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plota a curva ROC de teste\n",
    "plot_roc_curve(Y_train, Y_pred_proba_train, 'Regressão Logística - Treino')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plota um histograma com as probabilidades de churn\n",
    "df_result = pd.DataFrame({'Churn':Y_test, 'Churn_Prob':Y_pred_proba})\n",
    "sns.histplot(data=df_result,x = 'Churn_Prob',hue='Churn', bins=20, kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plota um histograma com as probabilidades de churn\n",
    "df_result = pd.DataFrame({'Churn':Y_train, 'Churn_Prob':Y_pred_proba_train})\n",
    "sns.histplot(data=df_result,x = 'Churn_Prob',hue='Churn', bins=20, kde=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Encontrando o Melhor Threshold"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2.1 Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faz as previsões com dados de teste\n",
    "Y_pred = modelo_gb.predict(X_test)\n",
    "Y_pred_proba = modelo_gb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# faz as previsões com dados de treino\n",
    "Y_pred_train = modelo_gb.predict(X_train)\n",
    "Y_pred_proba_train = modelo_gb.predict_proba(X_train)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inicializa a lista de scores\n",
    "score = []\n",
    "max_score = 0\n",
    "dif_minima = 1\n",
    "\n",
    "# loop para testar diferentes thresholds\n",
    "for threshold in np.arange(0.1, 0.9, 0.01):\n",
    "    # aplica o threshold na probabilidade\n",
    "    Y_pred_treshold = (Y_pred_proba > threshold).astype(int)\n",
    "\n",
    "    # calcula as métricas\n",
    "    vlr_f1_score = f1_score(Y_test, Y_pred_treshold)\n",
    "    vlr_recall_score = recall_score(Y_test, Y_pred_treshold)\n",
    "    vlr_precision_score = precision_score(Y_test, Y_pred_treshold)\n",
    "\n",
    "    # mínimo entre recall e precision\n",
    "    vlr_min_score = abs(vlr_recall_score - vlr_precision_score)\n",
    "    if vlr_min_score < dif_minima:\n",
    "        dif_minima = vlr_min_score\n",
    "        best_min_threshold = threshold\n",
    "\n",
    "    # salva o threshold e o score se ele for maior que o máximo\n",
    "    if vlr_f1_score > max_score:\n",
    "        max_score = vlr_f1_score\n",
    "        best_f1_threshold = threshold\n",
    "\n",
    "    # adiciona o resultado na lista\n",
    "    score.append((threshold,vlr_f1_score,vlr_recall_score,vlr_precision_score))\n",
    "print(f'O F1-Score máximo foi de {max_score:.2f} usando o threshold de {best_f1_threshold:.2f}')\n",
    "print(f'A menor diferença entre precision e recall foi de {dif_minima:.2f} usando o threshold de {best_min_threshold:.2f}')\n",
    "\n",
    "# threshold final do modelo de boosting\n",
    "threshold_gb = best_min_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotando o gráfico de F1-Score\n",
    "df_score = pd.DataFrame(score, columns=['threshold','f1_score','recall_score','precision_score'])\n",
    "ax = df_score.plot(x='threshold', y=['f1_score','recall_score','precision_score'], figsize=(10,5), grid=True)\n",
    "ax.axvline(best_f1_threshold, color=\"red\", linestyle=\"--\",label='Melhor F1')\n",
    "ax.axvline(best_min_threshold, color=\"black\", linestyle=\"--\",label='Precision = Recall')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2.2 Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faz as previsões com dados de teste\n",
    "Y_pred = modelo_rl.predict(X_test)\n",
    "Y_pred_proba = modelo_rl.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# faz as previsões com dados de treino\n",
    "Y_pred_train = modelo_rl.predict(X_train)\n",
    "Y_pred_proba_train = modelo_rl.predict_proba(X_train)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inicializa a lista de scores\n",
    "score = []\n",
    "max_score = 0\n",
    "dif_minima = 1\n",
    "\n",
    "# loop para testar diferentes thresholds\n",
    "for threshold in np.arange(0.1, 0.9, 0.01):\n",
    "    # aplica o threshold na probabilidade\n",
    "    Y_pred_treshold = (Y_pred_proba > threshold).astype(int)\n",
    "\n",
    "    # calcula as métricas\n",
    "    vlr_f1_score = f1_score(Y_test, Y_pred_treshold)\n",
    "    vlr_recall_score = recall_score(Y_test, Y_pred_treshold)\n",
    "    vlr_precision_score = precision_score(Y_test, Y_pred_treshold)\n",
    "\n",
    "    # mínimo entre recall e precision\n",
    "    vlr_min_score = abs(vlr_recall_score - vlr_precision_score)\n",
    "    if vlr_min_score < dif_minima:\n",
    "        dif_minima = vlr_min_score\n",
    "        best_min_threshold = threshold\n",
    "\n",
    "    # salva o threshold e o score se ele for maior que o máximo\n",
    "    if vlr_f1_score > max_score:\n",
    "        max_score = vlr_f1_score\n",
    "        best_f1_threshold = threshold\n",
    "\n",
    "    # adiciona o resultado na lista\n",
    "    score.append((threshold,vlr_f1_score,vlr_recall_score,vlr_precision_score))\n",
    "print(f'O F1-Score máximo foi de {max_score:.2f} usando o threshold de {best_f1_threshold:.2f}')\n",
    "print(f'A menor diferença entre precision e recall foi de {dif_minima:.2f} usando o threshold de {best_min_threshold:.2f}')\n",
    "\n",
    "# threshold final do modelo de regressão\n",
    "threshold_rl = best_min_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotando o gráfico de F1-Score\n",
    "df_score = pd.DataFrame(score, columns=['threshold','f1_score','recall_score','precision_score'])\n",
    "ax = df_score.plot(x='threshold', y=['f1_score','recall_score','precision_score'], figsize=(10,5), grid=True)\n",
    "ax.axvline(best_f1_threshold, color=\"red\", linestyle=\"--\",label='Melhor F1')\n",
    "ax.axvline(best_min_threshold, color=\"black\", linestyle=\"--\",label='Precision = Recall')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Fazendo Previsões e métricas finais"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.3.1 Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faz as previsões com dados de teste\n",
    "Y_pred = modelo_gb.predict(X_test)\n",
    "Y_pred_proba = modelo_gb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# faz as previsões com dados de treino\n",
    "Y_pred_train = modelo_gb.predict(X_train)\n",
    "Y_pred_proba_train = modelo_gb.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# aplica o threshold na probabilidade\n",
    "Y_pred_treshold = (Y_pred_proba > threshold_gb).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plota a matriz de confusão de teste\n",
    "plot_cm(Y_test, Y_pred_treshold, 'Gradient Boosting - Teste com Threshold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plota a curva ROC de teste\n",
    "plot_roc_curve(Y_test, Y_pred_proba, 'Gradient Boosting - Teste com Threshold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plota um histograma com as probabilidades de churn\n",
    "df_result = pd.DataFrame({'Churn':Y_test, 'Churn_Prob':Y_pred_proba})\n",
    "sns.histplot(data=df_result,x = 'Churn_Prob',hue='Churn', bins=20, kde=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.3.2 Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faz as previsões com dados de teste\n",
    "Y_pred = modelo_rl.predict(X_test)\n",
    "Y_pred_proba = modelo_rl.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# faz as previsões com dados de treino\n",
    "Y_pred_train = modelo_rl.predict(X_train)\n",
    "Y_pred_proba_train = modelo_rl.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# aplica o threshold na probabilidade\n",
    "Y_pred_treshold = (Y_pred_proba > threshold_rl).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plota a matriz de confusão de teste\n",
    "plot_cm(Y_test, Y_pred_treshold, 'Regressão Logística - Teste com Threshold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plota a curva ROC de teste\n",
    "plot_roc_curve(Y_test, Y_pred_proba, 'Regressão Logística - Teste com Threshold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plota um histograma com as probabilidades de churn\n",
    "df_result = pd.DataFrame({'Churn':Y_test, 'Churn_Prob':Y_pred_proba})\n",
    "sns.histplot(data=df_result,x = 'Churn_Prob',hue='Churn', bins=20, kde=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "daefdd352b271c3d14e155b13dd66aa6af60dc8f125bf3f5b458163bb8ef8801"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
